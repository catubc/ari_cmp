{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "%matplotlib tk\n",
    "%autosave 180\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "import cv2\n",
    "import time\n",
    "from numpy.linalg import norm \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy, scipy.io.wavfile\n",
    "from math import pi, cos, sin\n",
    "import os\n",
    "\n",
    "import sys\n",
    "# the mock-0.3.1 dir contains testcase.py, testutils.py & mock.py\n",
    "sys.path.append('/home/cat/Downloads/spinnaker_python-1.27.0.48-Ubuntu18.04-cp37-cp37m-linux_x86_64/Examples/Python3/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ari's function\n",
    "def get_cmp(stream_segment, templates, max_spikes, thresh):\n",
    "    \n",
    "    stream = stream_segment.copy()\n",
    "\n",
    "    chosen_L2 = [] \n",
    "    \n",
    "    T = stream.shape[0]-1#-55\n",
    "    \n",
    "    cmp = {}\n",
    "    c0=1\n",
    "    while True:\n",
    "        print (c0)\n",
    "        #convs = np.zeros([8,T+1])\n",
    "        convs = np.zeros([8,T+1])\n",
    "        for i in range(8):\n",
    "            convs[i,:] = 2*np.correlate(stream, templates[i,:], 'same') - norm(templates[i,:])**2\n",
    "        \n",
    "        amax= convs.argmax(1)\n",
    "        tte = convs[range(8),amax].argmax()\n",
    "        loc = amax[tte]\n",
    "\n",
    "        # exit condition based on energy threshold\n",
    "        maxval = convs[:,amax[tte]].max(0)\n",
    "        if maxval<thresh:\n",
    "            print (\"Threshold reachec, exiting \", maxval)\n",
    "            break\n",
    "        \n",
    "        #if c0 == max_spikes: \n",
    "        #    break   \n",
    "    \n",
    "        chosen_L2.append(convs[tte,loc])    \n",
    "        \n",
    "        start = -50\n",
    "        end = start+101\n",
    "\n",
    "        #fig=plt.figure()\n",
    "        #plt.plot(stream[loc+start:loc+end])\n",
    "        stream[loc+start:loc+end] -= templates[tte,:]\n",
    "        #plt.plot(stream[loc+start:loc+end])\n",
    "        c0+=1\n",
    "        \n",
    "        cmp[loc] = tte\n",
    "        plt.show()\n",
    "        \n",
    "        #if c0>3:\n",
    "        #    return\n",
    "    \n",
    "    lc = len(cmp)\n",
    "    cmp_ar = np.zeros([lc,2],dtype=np.int32)\n",
    "    cmp_ar[:,0] = np.sort(list(cmp.keys()))\n",
    "\n",
    "    for i in range(lc):\n",
    "        cmp_ar[i,1] = cmp[cmp_ar[i,0]]\n",
    "                \n",
    "    # shift times\n",
    "    cmp_ar[:,0]-=50\n",
    "    return cmp_ar, stream\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    943       0]\n",
      " [   1687       0]\n",
      " [   1947       0]\n",
      " ...\n",
      " [8996077       7]\n",
      " [8996652       7]\n",
      " [8997954       7]]\n",
      "(300000, 384)\n",
      "ground truth spike train for segment:  (2075, 2)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "fname = '/media/cat/4TBSSD/data/synthetic/ari/data_raw_30000hz_300sec_20hz_to_50hz.npy'\n",
    "data= np.load(fname)\n",
    "templates = np.load('/media/cat/4TBSSD/data/synthetic/ari/data_raw_30000hz_300sec_20hz_to_50hz_templates.npy')\n",
    "spikes = np.load('/media/cat/4TBSSD/data/synthetic/ari/data_raw_30000hz_300sec_20hz_to_50hz_times.npy',allow_pickle=True)\n",
    "\n",
    "# convert spike trains to usual 2-col format\n",
    "spike_train = np.zeros((0,2),'int32')\n",
    "for k in range(len(spikes)):\n",
    "    ids = np.zeros(spikes[k].shape[0], 'int32')+k\n",
    "    temp = np.vstack((spikes[k],ids)).T\n",
    "    spike_train = np.vstack((spike_train,temp))\n",
    "\n",
    "print (spike_train)\n",
    "\n",
    "# set some thresholds\n",
    "max_spikes = 1E8\n",
    "thresh = 10 #energy based threshold\n",
    "\n",
    "# flatten ends of data to avoid subtracting from ends and causing error\n",
    "buffer = 200\n",
    "\n",
    "# make a test datastream\n",
    "start = 0 + buffer\n",
    "end = 200000 - buffer\n",
    "data[:buffer]=0\n",
    "stream_segment = data[:end]\n",
    "stream_segment[-buffer:]=0\n",
    "\n",
    "# add correlated noise\n",
    "corr_noise = np.load('/media/cat/4TBSSD/data/synthetic/run11/correlated_noise.npy')\n",
    "print (corr_noise.shape)\n",
    "\n",
    "stream_segment+=corr_noise[100:100+stream_segment.shape[0],10]\n",
    "\n",
    "# visualize stream if required\n",
    "#plt.plot(stream_segment)\n",
    "\n",
    "# grab spikes from streamed_segment\n",
    "idx = np.where(np.logical_and(spike_train[:,0]>start, spike_train[:,0]<=end))[0]\n",
    "spk_gt = spike_train[idx]\n",
    "print (\"ground truth spike train for segment: \", spk_gt.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fname_out = fname[:-4]+'_res.npz'\n",
    "\n",
    "if os.path.exists(fname_out)==False:\n",
    "    # run CMP\n",
    "    spk_cmp, stream_deconv = get_cmp(stream_segment, templates, \n",
    "                                    max_spikes,\n",
    "                                   thresh)\n",
    "    print (spk_cmp)\n",
    "\n",
    "    np.savez(fname_out,\n",
    "            spk_cmp=spk_cmp,\n",
    "             stream_deconv=stream_deconv)\n",
    "\n",
    "else:\n",
    "    data = np.load(fname_out)\n",
    "    spk_cmp = data['spk_cmp']\n",
    "    stream_deconv = data['stream_deconv']\n",
    "    \n",
    "fig=plt.figure()\n",
    "plt.plot(stream_segment)\n",
    "plt.plot(stream_deconv)\n",
    "plt.plot(corr_noise[100:100+stream_segment.shape[0],10],color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname_out = fname[:-4]+'_res.npz'\n",
    "\n",
    "# np.savez(fname_out,\n",
    "#             spk_cmp=spk_cmp,\n",
    "#              stream_deconv=stream_deconv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cat/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:46: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "/home/cat/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:58: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
     ]
    }
   ],
   "source": [
    "# compute errors per unit and plot against time\n",
    "ptps = templates.ptp(1)\n",
    "\n",
    "fnames = ['/media/cat/4TBSSD/data/synthetic/ari/data_raw_30000hz_300sec_20hz_to_50hz_res_no_noise.npz',\n",
    "         '/media/cat/4TBSSD/data/synthetic/ari/data_raw_30000hz_300sec_20hz_to_50hz_res.npz']\n",
    "\n",
    "clrs = ['blue','red']\n",
    "fig = plt.figure()\n",
    "ctr=0\n",
    "labels = [\"No Correlated Noise Data\",\"Correlated Noise Data\"]\n",
    "for fname in fnames:\n",
    "    \n",
    "    data = np.load(fname)\n",
    "    spk_cmp = data['spk_cmp']\n",
    "    stream_deconv = data['stream_deconv']\n",
    "    \n",
    "    # count # of spikes in each cluster\n",
    "    n_cmp_spikes = []\n",
    "    for k in range(templates.shape[0]):\n",
    "        n_cmp_spikes.append(np.where(spk_cmp[:,1]==k)[0].shape[0])\n",
    "    n_cmp_spikes = np.array(n_cmp_spikes)\n",
    "\n",
    "    # match units\n",
    "    matches_tp = np.zeros(templates.shape[0])\n",
    "    n_spikes_gt = np.zeros(templates.shape[0],'float32')\n",
    "    for k in range(spk_gt.shape[0]):\n",
    "        time = spk_gt[k,0]\n",
    "        id_ = spk_gt[k,1]\n",
    "\n",
    "        n_spikes_gt[id_]+=1\n",
    "\n",
    "        # pull out deconvolved spike train for particular unit\n",
    "        idx = np.where(spk_cmp[:,1]==id_)[0]\n",
    "\n",
    "        if idx.shape[0]==0:\n",
    "            continue\n",
    "        # match to within 5 timesteps\n",
    "        if np.min(np.abs(spk_cmp[idx] - time))<5:\n",
    "            matches_tp[id_]+=1\n",
    "\n",
    "    # reorder by ptp\n",
    "    idx = np.argsort(ptps)\n",
    "    matches_tp = matches_tp[idx]\n",
    "    n_cmp_spikes = n_cmp_spikes[idx]\n",
    "\n",
    "    ax1=plt.subplot(121)\n",
    "    # \n",
    "    plt.title(\"True Positives \", fontsize=20)\n",
    "    n_spikes_gt = n_spikes_gt[idx]\n",
    "    ax1.scatter(ptps[idx], matches_tp/n_spikes_gt, c=clrs[ctr], label=labels[ctr])\n",
    "    plt.ylim(0, 1.1)\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.ylabel(\"Rates\", fontsize=20)\n",
    "    ax1.tick_params(axis = 'both', which = 'major', labelsize = 20)\n",
    "    plt.xlabel(\"PTPs\", fontsize=20)\n",
    "\n",
    "    # \n",
    "    ax2=plt.subplot(122)\n",
    "    plt.title(\"False Positives \", fontsize=20)\n",
    "    ax2.scatter(ptps[idx], (n_cmp_spikes-matches_tp)/n_cmp_spikes, c=clrs[ctr], label=labels[ctr])\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.ylim(0, 1.1)\n",
    "    plt.xlim(0,60)\n",
    "    plt.xlabel(\"PTPs\", fontsize=20)\n",
    "    ax2.tick_params(axis = 'both', which = 'major', labelsize = 20)\n",
    "\n",
    "    #plt.title(\"CMP on time series length: \"+str(round((end-start)/20000.,1))+\" sec\",fontsize=20)\n",
    "\n",
    "    ctr+=1\n",
    "plt.suptitle(fname, fontsize=20)\n",
    "plt.show()\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
