{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "%matplotlib tk\n",
    "%autosave 180\n",
    "\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "#from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "#from statsmodels import robust\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as mpatches\n",
    "import os\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# run pca and visualize\n",
    "\n",
    "import scipy\n",
    "\n",
    "colors = [\n",
    "'black','blue','red','green','cyan','magenta','brown','pink',\n",
    "'orange','firebrick','lawngreen','dodgerblue','crimson','orchid','slateblue',\n",
    "'darkgreen','darkorange','indianred','darkviolet','deepskyblue','greenyellow',\n",
    "'peru','cadetblue','forestgreen','slategrey','lightsteelblue','rebeccapurple',\n",
    "'darkmagenta','yellow','hotpink']\n",
    "\n",
    "sorted_colors=colors\n",
    "\n",
    "#import deconv\n",
    "\n",
    "# visualize recomputed templates over time;\n",
    "def binary_reader_waveforms(filename, n_channels, n_times, spikes, channels=None, data_type='float32'):\n",
    "    ''' Reader for loading raw binaries\n",
    "    \n",
    "        standardized_filename:  name of file contianing the raw binary\n",
    "        n_channels:  number of channels in the raw binary recording \n",
    "        n_times:  length of waveform \n",
    "        spikes: 1D array containing spike times in sample rate of raw data\n",
    "        channels: load specific channels only\n",
    "        data_type: float32 for standardized data\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # ***** LOAD RAW RECORDING *****\n",
    "    if channels is None:\n",
    "        wfs = np.zeros((spikes.shape[0], n_times, n_channels), data_type)\n",
    "    else:\n",
    "        wfs = np.zeros((spikes.shape[0], n_times, channels.shape[0]), data_type)\n",
    "    if data_type =='float32':\n",
    "        data_len = 4\n",
    "    else:\n",
    "        data_len = 2\n",
    "\n",
    "    with open(filename, \"rb\") as fin:\n",
    "        for ctr,s in enumerate(spikes):\n",
    "            #print (ctr,s)\n",
    "            # index into binary file: time steps * 4  4byte floats * n_channels\n",
    "            fin.seek(s * data_len * n_channels, os.SEEK_SET)\n",
    "            wfs[ctr] = np.fromfile(\n",
    "                fin,\n",
    "                dtype=data_type,\n",
    "                count=(n_times * n_channels)).reshape(n_times, n_channels)[:,channels]\n",
    "    fin.close()\n",
    "    return wfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n",
      "(0,)\n",
      "(3,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(1,)\n",
      "(2,)\n",
      "(1,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(2,)\n",
      "(3,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('/media/cat/12TB/insync_cm3746/paninski_lab/data/neuropixels/ari/julien_real_neighbour_chans_neuropixels2/chan_5_data.npy')\n",
    "templates = np.load('/media/cat/12TB/insync_cm3746/paninski_lab/data/neuropixels/ari/julien_real_neighbour_chans_neuropixels2/chan_5_templates.npy',allow_pickle=True)\n",
    "times = np.load('/media/cat/12TB/insync_cm3746/paninski_lab/data/neuropixels/ari/julien_real_neighbour_chans_neuropixels2/chan_5_times.npy',allow_pickle=True)\n",
    "plt.plot(data[:10000])\n",
    "for p in range(templates.shape[0]):\n",
    "    idx = np.where(times[p]<10000)[0]\n",
    "    print (idx.shape)\n",
    "    for k in range(idx.shape[0]):\n",
    "        plt.plot(times[p][k]+np.arange(75)-9,templates[p],c=colors[p])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072000000,)\n",
      "(6000000, 512)\n",
      "[[        0      1430]\n",
      " [        0       490]\n",
      " [        0       565]\n",
      " ...\n",
      " [143999995       239]\n",
      " [143999996       812]\n",
      " [143999997        17]]\n"
     ]
    }
   ],
   "source": [
    "# YASS DATASETS\n",
    "# load raw data and spike train\n",
    "root_dir = '/media/cat/12TB/insync_cm3746/paninski_lab/data/retina/512chan/ari_Julien_CMP/2009_real_retina_data/data/'\n",
    "\n",
    "temps = np.load('/media/cat/2TB/liam/512channels/2009-04-13-5_120mins/tmp/output/templates/templates_0sec.npy')\n",
    "print (temps.shape)\n",
    "\n",
    "geom = np.loadtxt('/media/cat/2TB/liam/512channels/2009-04-13-5_120mins/geom.txt')\n",
    "\n",
    "\n",
    "data = np.fromfile('/media/cat/2TB/liam/512channels/2009-04-13-5_120mins/tmp/preprocess/standardized.bin','float32')\n",
    "print (data.shape)\n",
    "\n",
    "n_chan = 512\n",
    "data2D = data.reshape(-1,n_chan)\n",
    "print (data2D.shape)\n",
    "\n",
    "spike_train = np.load('/media/cat/2TB/liam/512channels/2009-04-13-5_120mins/tmp/output/spike_train.npy')\n",
    "print (spike_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " templates saved:  (29, 75)\n",
      " templates saved:  (22, 75)\n",
      " templates saved:  (21, 75)\n",
      " templates saved:  (21, 75)\n",
      " templates saved:  (25, 75)\n",
      " templates saved:  (19, 75)\n",
      " templates saved:  (49, 75)\n",
      " templates saved:  (52, 75)\n",
      " templates saved:  (59, 75)\n",
      " templates saved:  (53, 75)\n",
      " templates saved:  (61, 75)\n",
      " templates saved:  (53, 75)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/cat/12TB/insync_cm3746/paninski_lab/data/retina/512chan/ari_Julien_CMP/2009_real_retina_data/data//chan_11_times.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-93b6547a6085>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         np.save(root_dir+'/chan_'+str(ctr)+'_times.npy',\n\u001b[0;32m---> 63\u001b[0;31m                 times_out)\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;31m#break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mctr\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msave\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/cat/12TB/insync_cm3746/paninski_lab/data/retina/512chan/ari_Julien_CMP/2009_real_retina_data/data//chan_11_times.npy'"
     ]
    }
   ],
   "source": [
    "# save channels with > 3 templates on them\n",
    "ptps = temps.ptp(1).max(1)\n",
    "max_chans = temps.ptp(1).argmax(1)\n",
    "\n",
    "\n",
    "root_dir = '/media/cat/12TB/insync_cm3746/paninski_lab/data/retina/512chan/ari_Julien_CMP/2009_real_retina_data/data/'\n",
    "\n",
    "\n",
    "ctr=0\n",
    "for chan in range(n_chan):\n",
    "    idx2 = np.where(max_chans==chan)[0]\n",
    "    ptps_local = ptps[idx2]\n",
    "\n",
    "    locs = geom[chan]\n",
    "    \n",
    "    thresh=70\n",
    "    \n",
    "    chans_neighbour = []\n",
    "    for k in range(n_chan):\n",
    "        dist = np.linalg.norm(locs-geom[k])\n",
    "        if dist < thresh:\n",
    "            chans_neighbour.append(k)\n",
    "\n",
    "            \n",
    "    #print (chans_neighbour)\n",
    "    #break\n",
    "    # all chans within neighbourhood\n",
    "    chans_neighbour = np.unique(chans_neighbour)\n",
    "       \n",
    "    #idx3 = np.where(ptps_local>8.0)[0]\n",
    "    \n",
    "    \n",
    "    if idx2.shape[0]>5:\n",
    "                \n",
    "        # save this channel and the data\n",
    "        np.save(root_dir+'/chan_'+str(ctr)+'_data.npy',\n",
    "                data2D[:,chan])\n",
    "        \n",
    "        # save templates\n",
    "        temps_out=[]\n",
    "        for ch in chans_neighbour:\n",
    "            idx = np.where(max_chans==ch)[0]\n",
    "            temps_out.extend(temps[idx,:,chan])  #Make sure you save max channel tempalte NOT \n",
    "            \n",
    "        temps_out = np.array(temps_out)[:,20:95]\n",
    "        print (\" templates saved: \", temps_out.shape)\n",
    "            \n",
    "        np.save(root_dir+'/chan_'+str(ctr)+'_templates.npy',\n",
    "                temps_out)\n",
    "        \n",
    "        # save spiketrains\n",
    "        times_out= []\n",
    "        for ch in chans_neighbour:\n",
    "            #idx = np.where\n",
    "            ids = np.where(max_chans==ch)[0]\n",
    "            for id_ in ids:\n",
    "                idx4 = np.where(spike_train[:,1]==id_)[0]\n",
    "                times = spike_train[idx4,0]\n",
    "                idx5 = np.where(times<(5*60*20000))[0]\n",
    "                times_out.append(times[idx5])\n",
    "        \n",
    "        np.save(root_dir+'/chan_'+str(ctr)+'_times.npy',\n",
    "                times_out)\n",
    "        #break    \n",
    "        ctr+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072000000,)\n"
     ]
    }
   ],
   "source": [
    "data = np.fromfile('/media/cat/2TB/liam/512channels/2009-04-13-5_120mins/2009-04-13-5.bin','int16',count=512*20000*5*60)\n",
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tofile('/media/cat/2TB/liam/512channels/2009-04-13-5_120mins/2009-04-13-5_5min.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
